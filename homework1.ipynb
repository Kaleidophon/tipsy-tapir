{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Information retrieval --- Module 1: Evaulation\n",
    "Santhosh Kumar Rajamanickam, Dennis Ulmer and Stian Steinbakken\n",
    "\n",
    "TODO: Maybe insert a small introduction here? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical part [15pts]\n",
    "### 1 Hypothesis Testing --- The problem of multiple comparisons. \n",
    "How many hypothesis tests, m, does it take to get to (with Type I error for each test = α):\n",
    "1. P(mth experiment gives significant result | m experiments lacking power to reject H0)?\n",
    "2. P(at least one significant result | m experiments lacking power to reject H0)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "1. Because the outcome of the experiments are independent, we can just multiply the probabilities of the outcomes in this question. The probability of an experiment giving a significant result, i.e. rejecting the Null Hypothesis, will be $\\alpha$. Likewise, the probability of experiments lacking the power to reject $H_0$ will be $1-\\alpha$. Therefore\n",
    "\n",
    "\\begin{equation}\n",
    "P(m^{th}\\text{ experiment gives significant result } | \\ m\\text{ experiments lacking power to reject } H_0) = (1-\\alpha)^{m-1}\\alpha\n",
    "\\end{equation}\n",
    "\n",
    "2. The probability of at least one in $m$ experiments rejecting the Null Hypothesis falsely is the sum of the probabilities of a experiment at time step $t$ rejecting the Null-Hypothesis conditioned on the previous experiments rejecting it correctly:\n",
    "\n",
    "\\begin{equation}\n",
    "   p(\\text{rejecting the Null Hypothesis at least once}|m\\text{ experiments lacking power to reject }H_0)\\\\ = p(1^{st}\\text{ wrong}) + p(2^{nd} \\text{wrong}\\ |\\ 1^{st}\\ \\text{right}) + \\ldots + p(m^{th} \\text{wrong}\\ |\\ \\text{all}\\ m-1\\ \\text{experiments}\\ \\text{right})\\\\\n",
    "   = \\alpha + (\\alpha - 1)\\alpha + (\\alpha-1)^2\\alpha + \\ldots + (\\alpha-1)^{m-1}\\alpha\\\\\n",
    "   = \\alpha \\cdot {\\displaystyle \\sum_{t=0}^{m-1}} (\\alpha-1)^t\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Bias and unfairness in Interleaving experiments [10 points]\n",
    "Balance interleaving has been shown to be biased in a number of corner cases. An example was given during the lecture with two ranked lists of length 3 being interleaved, and a randomly clicking population of users that resulted in algorithm A winning ⅔ of the time, even though in theory the percentage of wins should be 50% for both algorithms. Can you come up with a situation of two ranked lists of length 3 and a distribution of clicks over them for which Team-draft interleaving is unfair to the better algorithm?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "Assume we have to algorithms A and B providing documents for an interleaved ranking of length $3$, where A is the worse algorithm. While constructing the interleaved ranking, the result of two coin tosses where A wins gives A preference to place its documents first. Because we only have three entries, two of the entries will originate from A and only one from B.\n",
    "\n",
    "Given random clicking, A will again win ⅔ of times. Here the unfairness is due to the coin tosses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental part [85 pts] \n",
    "Step 1: Simulate Rankings of Relevance for E and P (5 points)\n",
    "In the first step you will generate pairs of rankings of relevance, for the production P and experimental E, respectively, for a hypothetical query q. Assume a 3-graded relevance, i.e. {N, R, HR}. Construct all possible P and E ranking pairs of length 5. This step should give you about.\n",
    "\n",
    "Example:\n",
    "P: {N N N N N}\n",
    "E: {N N N N R}\n",
    "…\n",
    "P: {HR HR HR HR R}\n",
    "E: {HR HR HR HR HR}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59049 simulations in total.\n",
      "\n",
      "First 10 simulations:\n",
      "\n",
      "P: ('N', 'N', 'N', 'N', 'N'), E: ('N', 'N', 'N', 'N', 'N')\n",
      "P: ('N', 'N', 'N', 'N', 'N'), E: ('N', 'N', 'N', 'N', 'R')\n",
      "P: ('N', 'N', 'N', 'N', 'N'), E: ('N', 'N', 'N', 'N', 'HR')\n",
      "P: ('N', 'N', 'N', 'N', 'N'), E: ('N', 'N', 'N', 'R', 'N')\n",
      "P: ('N', 'N', 'N', 'N', 'N'), E: ('N', 'N', 'N', 'R', 'R')\n",
      "P: ('N', 'N', 'N', 'N', 'N'), E: ('N', 'N', 'N', 'R', 'HR')\n",
      "P: ('N', 'N', 'N', 'N', 'N'), E: ('N', 'N', 'N', 'HR', 'N')\n",
      "P: ('N', 'N', 'N', 'N', 'N'), E: ('N', 'N', 'N', 'HR', 'R')\n",
      "P: ('N', 'N', 'N', 'N', 'N'), E: ('N', 'N', 'N', 'HR', 'HR')\n",
      "P: ('N', 'N', 'N', 'N', 'N'), E: ('N', 'N', 'R', 'N', 'N')\n",
      "\n",
      "Last 10 simulations:\n",
      "\n",
      "P: ('HR', 'HR', 'HR', 'HR', 'HR'), E: ('HR', 'HR', 'R', 'HR', 'HR')\n",
      "P: ('HR', 'HR', 'HR', 'HR', 'HR'), E: ('HR', 'HR', 'HR', 'N', 'N')\n",
      "P: ('HR', 'HR', 'HR', 'HR', 'HR'), E: ('HR', 'HR', 'HR', 'N', 'R')\n",
      "P: ('HR', 'HR', 'HR', 'HR', 'HR'), E: ('HR', 'HR', 'HR', 'N', 'HR')\n",
      "P: ('HR', 'HR', 'HR', 'HR', 'HR'), E: ('HR', 'HR', 'HR', 'R', 'N')\n",
      "P: ('HR', 'HR', 'HR', 'HR', 'HR'), E: ('HR', 'HR', 'HR', 'R', 'R')\n",
      "P: ('HR', 'HR', 'HR', 'HR', 'HR'), E: ('HR', 'HR', 'HR', 'R', 'HR')\n",
      "P: ('HR', 'HR', 'HR', 'HR', 'HR'), E: ('HR', 'HR', 'HR', 'HR', 'N')\n",
      "P: ('HR', 'HR', 'HR', 'HR', 'HR'), E: ('HR', 'HR', 'HR', 'HR', 'R')\n",
      "P: ('HR', 'HR', 'HR', 'HR', 'HR'), E: ('HR', 'HR', 'HR', 'HR', 'HR')\n"
     ]
    }
   ],
   "source": [
    "# Step 1 code\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "\n",
    "RankingPair = namedtuple(\"RankingPair\", [\"E\", \"P\"])\n",
    "\n",
    "RANKINGS = (\"N\", \"R\", \"HR\")\n",
    "\n",
    "simulations = []\n",
    "\n",
    "# Create all possible rankings of length 5\n",
    "for ranking_pair in list(product(list(product(RANKINGS, repeat=5)), repeat=2)):\n",
    "    simulations.append(RankingPair(*ranking_pair))\n",
    "\n",
    "print(\"{} simulations in total.\\n\".format(len(simulations)))\n",
    "    \n",
    "print(\"First 10 simulations:\\n\")\n",
    "for ranking_pair in simulations[:10]:\n",
    "    print(\"P: {}, E: {}\".format(*ranking_pair))\n",
    "    \n",
    "print(\"\\nLast 10 simulations:\\n\")\n",
    "for ranking_pair in simulations[-10:]:\n",
    "    print(\"P: {}, E: {}\".format(*ranking_pair))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 2: Implement Evaluation Measures (10 points)\n",
    "Implement 1 binary and 2 multi-graded evaluation measures out of the 7 measures mentioned above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All average-precision tests passed\n"
     ]
    }
   ],
   "source": [
    "# Implementation of Average Precision (AP)\n",
    "\n",
    "def precision(rankings):\n",
    "    relevant_tags = (RANKINGS[1], RANKINGS[2]) # 'R' and 'HR'\n",
    "    \n",
    "    relevant_rankings = sum([1 for rank in rankings if rank in relevant_tags])\n",
    "    return relevant_rankings / len(rankings) \n",
    "\n",
    "# For our binary evaulation meassure we implement average precision (AP)\n",
    "def average_precision(rankings, num_relevant=None):\n",
    "    if num_relevant == None:\n",
    "        num_relevant = len(rankings)\n",
    "    relevant_tags = (RANKINGS[1], RANKINGS[2]) # 'R' and 'HR'\n",
    "    return sum([precision(rankings[:i+1]) for i in range(len(rankings)) if rankings[i] in relevant_tags]) / num_relevant\n",
    "\n",
    "def test_average_precision():\n",
    "    example_rank_1 = ('R', 'R', 'R', 'R', 'R')\n",
    "    example_rank_2 = ('N', 'N', 'N', 'N', 'N')\n",
    "    example_rank_3 = ('N', 'R', 'N', 'N', 'R')\n",
    "    \"\"\"\n",
    "    Example rank 3 should yield (1/2 + 2/5) / 5 = (0.5 + 0.4) / 5 = 0.18\n",
    "    \"\"\"\n",
    "    \n",
    "    assert average_precision(example_rank_1) == 1\n",
    "    assert average_precision(example_rank_2) == 0\n",
    "    assert average_precision(example_rank_3) == 0.18\n",
    "    return True\n",
    "\n",
    "AP_passed = test_average_precision()\n",
    "if AP_passed: print(\"All average-precision tests passed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementation of Normalized Discounted Cumulative Gain at rank k (nDCG@k)\n",
    "import math\n",
    "from functools import cmp_to_key\n",
    "\n",
    "# Assumptation\n",
    "RANKING_WEIGHTS = {\"N\": 0, \"R\": 1, \"HR\": 5}\n",
    "\n",
    "def sort_ranks(ranks):\n",
    "    \"\"\" Sort ranks by relevance, assuming HR > R > N. \"\"\"\n",
    "    def sort_func(rank1, rank2):\n",
    "        if rank1 == rank2:\n",
    "            return 0\n",
    "        elif rank1 == \"HR\":\n",
    "            return 1\n",
    "        elif rank2 == \"HR\":\n",
    "            return -1\n",
    "        elif rank1 == \"R\":\n",
    "            return 1\n",
    "        elif rank2 == \"R\":\n",
    "            return -1\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    return sorted(ranks, key=cmp_to_key(sort_func), reverse=True)\n",
    "\n",
    "def ndcg(ranks, gain=lambda rank: 2**RANKING_WEIGHTS[rank]-1, k=5):\n",
    "    # Calculate dcg, but normalize by the ideal dcg for this list,\n",
    "    # which would be the list with their elements sorted in a descending order.\n",
    "    try:\n",
    "        return dcg(ranks, gain, k) / dcg(sort_ranks(ranks), gain, k)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "def dcg(ranks, gain=lambda rank: 2**RANKING_WEIGHTS[rank]-1, k=5):\n",
    "    return sum([gain(rank) / math.log(2+i, 2) for i, rank in enumerate(ranks[:k])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementation of Expected Reciprocal Rank (ERR)\n",
    "\n",
    "def sat_prob_mapping(grade, grade_max=5):\n",
    "    return ((2**grade)-1)/2**grade_max\n",
    "\n",
    "def err(rankings):\n",
    "    return sum([ (1/(i+1))*sat_prob_mapping(RANKING_WEIGHTS[grade]) for i, grade in enumerate(rankings)])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate the 𝛥measure (10 points)\n",
    "For the three measures and all P and E ranking pairs constructed above calculate the difference: 𝛥measure = measureE-measureP. Consider only those pairs for which E outperforms P.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delta_measure(simulations, measure_to_test):\n",
    "    # Measure_to_test argument must be a function that takes in a ranking to be measured\n",
    "    # We do this so that the function can be re-used for each of the measures\n",
    "    results = []\n",
    "    \n",
    "    for sim in simulations:\n",
    "        E_ranking, P_ranking = sim\n",
    "        P_measure, E_measure = measure_to_test(P_ranking), measure_to_test(E_ranking)\n",
    "        \n",
    "        results.append(E_measure - P_measure if E_measure > P_measure else 0)\n",
    "    return results\n",
    "        \n",
    "delta_m_AP = delta_measure(simulations, average_precision)\n",
    "delta_m_ndcg = delta_measure(simulations, ndcg)\n",
    "#print(\"Delta_m for average_precision:\", delta_m_AP)\n",
    "#print(\"Delta_m for Normalized Discounted Cumulative Gain:\", delta_m_ndcg)\n",
    "\n",
    "# TODO: Run delta_measure for the remaining measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Interleaving (15 points)\n",
    "Implement 2 interleaving algorithms: (1) Team-Draft Interleaving OR Balanced Interleaving, AND (2), Probabilistic Interleaving. The interleaving algorithms should (a) given two rankings of relevance interleave them into a single ranking, and (b) given the users clicks on the interleaved ranking assign credit to the algorithms that produced the rankings.\n",
    "\n",
    "(Note 4: Note here that as opposed to a normal interleaving experiment where rankings consists of urls or docids, in our case the rankings consist of relevance labels. Hence in this case (a) you will assume that E and P return different documents, (b) the interleaved ranking will also be a ranking of labels.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'R', 'N', 'R', 'R']\n"
     ]
    }
   ],
   "source": [
    "# Step 4 code\n",
    "# TODO: Stian (I can do both)\n",
    "# TODO: Assign credit\n",
    "from random import choice \n",
    "\n",
    "def team_draft_interleaving(rankings_1, rankings_2, interleaved_rankings_size=5):\n",
    "    interleaved_rankings = []\n",
    "    i = -1\n",
    "    \n",
    "    # TODO: Use all entries in ranking 1 and 2 for interleaving\n",
    "    while len(interleaved_rankings) < interleaved_rankings_size:\n",
    "        i += 1\n",
    "        \n",
    "        if choice([\"H\", \"T\"]) == \"H\":\n",
    "            interleaved_rankings.append(rankings_1[i])\n",
    "            \n",
    "            if len(interleaved_rankings) < interleaved_rankings_size:\n",
    "                interleaved_rankings.append(rankings_2[i])\n",
    "        else:\n",
    "            interleaved_rankings.append(rankings_2[i])\n",
    "            \n",
    "            if len(interleaved_rankings) < interleaved_rankings_size:\n",
    "                interleaved_rankings.append(rankings_1[i])\n",
    "            \n",
    "    return interleaved_rankings\n",
    "\n",
    "example_rank_1 = ('R', 'R', 'R', 'R', 'R')\n",
    "example_rank_2 = ('N', 'N', 'N', 'N', 'N')\n",
    "\n",
    "interleaved = team_draft_interleaving(example_rank_1, example_rank_2)\n",
    "print(interleaved)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement User Clicks Simulation (15 points)\n",
    "Having interleaved all the ranking pairs an online experiment could be ran. However, given that we do not have any users (and the entire homework is a big simulation) we will simulate user clicks.\n",
    "\n",
    "We have considered a number of click models including:\n",
    "1. Random Click Model (RCM)\n",
    "2. Position-Based Model (PBM)\n",
    "3. Simple Dependent Click Model (SDCM)\n",
    "4. Simple Dynamic Bayesian Network (SDBN)\n",
    "\n",
    "Consider two different click models, (a) the Random Click Model (RCM), and (b) one out of the remaining 3 aforementioned models. The parameters of some of these models can be estimated using the Maximum Likelihood Estimation (MLE) method, while others require using the Expectation-Maximization (EM) method. Implement the two models so that (a) there is a method that learns the parameters of the model given a set of training data, (b) there is a method that predicts the click probability given a ranked list of relevance labels, (c) there is a method that decides - stochastically - whether a document is clicked based on these probabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<YandexData comprising 11716 sessions> \n",
      "\n",
      "<Session #5>\n",
      "<Session #6>\n",
      "<Session #7>\n",
      "<Session #8>\n",
      "<Session #9>\n",
      "\n",
      "<Query #0 in session #0>\n",
      "<Query #0 in session #0>\n",
      "<Query #0 in session #0>\n",
      "<Query #0 in session #0>\n",
      "<Query #0 in session #0>\n",
      "\n",
      "<Click in session #0 on #17562>\n",
      "<Click in session #0 on #1627>\n",
      "<Click in session #0 on #1626>\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "from collections import defaultdict\n",
    "\n",
    "class YandexData:\n",
    "    \"\"\" Class to represent the entire dataset. \"\"\"\n",
    "    def __init__(self, sessions={}):\n",
    "        self.page_length = 10  # Number of result on every page\n",
    "        self.sessions = sessions\n",
    "        self.docid2sessions = defaultdict(list)  # Return the sessions a specific document is in\n",
    "        self.queryid2sessions = defaultdict(list)  # Return the sessions a specific query is in\n",
    "        self.querydocid2rank = defaultdict(int)  # Return the rank of a document in a specific query\n",
    "        self.querydocid2sessions = defaultdict(list)\n",
    "        \n",
    "    def add(self, session):\n",
    "        self.sessions[session.uid] = session\n",
    "        \n",
    "        # Store in which sessions this document occurs\n",
    "        for document_id in session.documents:\n",
    "            self.docid2sessions[document_id].append(session.uid)\n",
    "            \n",
    "        # Store in which session this query occurs\n",
    "        for query in session.queries:\n",
    "            self.queryid2sessions[query.query_id].append(session.uid)\n",
    "            \n",
    "            # Store in which session this query and document occurs\n",
    "            for document_id in query.document_ids:\n",
    "                self.querydocid2sessions[(query.query_id, document_id)].append(session.uid)\n",
    "            \n",
    "        # Store what rank a document had given a query\n",
    "        current_query_id = 0\n",
    "        current_page_count = -1\n",
    "        current_serps = set()\n",
    "        for query in session.queries:\n",
    "            if query.serp_id in current_serps:\n",
    "                continue\n",
    "            \n",
    "            if query.query_id == current_query_id:\n",
    "                current_page_count += 1\n",
    "                current_serps.add(query.serp_id)\n",
    "            else:\n",
    "                current_query_id = query.query_id\n",
    "                current_page_count = -1\n",
    "                current_serps = set()\n",
    "            \n",
    "            for i, document_id in enumerate(query.document_ids):\n",
    "                self.querydocid2rank[(document_id, query.query_id)] = i + current_page_count * 10\n",
    "                #print(\"Adding doc #{} for query #{} with rank {}\".format(document_id, query.query_id, i + current_page_count * 10 + 1))\n",
    "            \n",
    "        \n",
    "    def __getitem__(self, items):\n",
    "        return list(self.sessions.values())[items]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return (session for session in self.sessions.values())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sessions)\n",
    "    \n",
    "    @property\n",
    "    def queries(self):\n",
    "        \"\"\" Return all queries in the entire data set. \"\"\"\n",
    "        for session in self:\n",
    "            for query in session.queries:\n",
    "                yield query\n",
    "                \n",
    "    @property\n",
    "    def clicks(self):\n",
    "        \"\"\" Return all clicks in the entire data set. \"\"\"\n",
    "        for session in self:\n",
    "            for click in session.clicks:\n",
    "                yield click\n",
    "                \n",
    "    def __repr__(self):\n",
    "        return \"<YandexData comprising {} sessions>\".format(len(self))\n",
    "\n",
    "\n",
    "class Session:\n",
    "    def __init__(self, uid, user_actions):\n",
    "        self.uid = uid\n",
    "        self.user_actions = user_actions\n",
    "        self._queries = None\n",
    "        self._clicks = None\n",
    "        self._documents = None\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return (user_action for user_action in self.user_actions)\n",
    "    \n",
    "    def __contains__(self, element):\n",
    "        return element in self.documents\n",
    "    \n",
    "    def rank_of_document(self, document_id):\n",
    "        rank = self.documents.index(document_id)\n",
    "        \n",
    "        if rank == -1:\n",
    "            raise IndexError(\"Document ID #{} not found in session #{}.\".format(document_id, self.uid))\n",
    "        \n",
    "        return rank\n",
    "    \n",
    "    def document_at_rank(self, rank):\n",
    "        return self.documents[rank]\n",
    "    \n",
    "    def has_been_clicked(self, document_id):\n",
    "        for click in self.clicks:\n",
    "            if document_id == click.document_id:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    @property\n",
    "    def queries(self):\n",
    "        \"\"\" Return all queries in this session. \"\"\"\n",
    "        if self._queries == None:\n",
    "            self._queries = [action for action in self.user_actions if action.action_type == \"Q\"]\n",
    "        return self._queries\n",
    "    \n",
    "    @property\n",
    "    def clicks(self):\n",
    "        \"\"\" Return all clicks in this session. \"\"\"\n",
    "        if self._clicks == None:\n",
    "            self._clicks = [action for action in self.user_actions if action.action_type == \"C\"]\n",
    "        return self._clicks\n",
    "    \n",
    "    @property\n",
    "    def documents(self):\n",
    "        \"\"\" Return all documents in this session. \"\"\"\n",
    "        if self._documents == None:\n",
    "\n",
    "            document_ids = []\n",
    "\n",
    "            # TODO: Consider all documents shown or just unique documents?\n",
    "            for query in self.queries:\n",
    "                document_ids.extend(query.document_ids)\n",
    "\n",
    "            self._documents = document_ids\n",
    "            \n",
    "        return self._documents\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"<Session #{}>\".format(self.uid)\n",
    "        \n",
    "\n",
    "class UserAction:\n",
    "    def __init__(self, session_id, time_passed, action_type, *document_ids):\n",
    "        self.session_id = session_id\n",
    "        self.time_passed = time_passed\n",
    "        self.action_type = action_type\n",
    "        self.document_ids = document_ids\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return (document_id for document_id in self.document_ids)\n",
    "            \n",
    "    def __contains__(self, document_id):\n",
    "        return document_id in self.document_ids\n",
    "        \n",
    "class Query(UserAction):\n",
    "    def __init__(self, session_id, time_passed, serp_id, query_id, *document_ids):\n",
    "        self.query_id = query_id\n",
    "        self.serp_id = serp_id\n",
    "        super().__init__(session_id, time_passed, \"Q\", *document_ids)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"<Query #{} in session #{}>\".format(self.query_id, self.session_id)\n",
    "        \n",
    "        \n",
    "class Click(UserAction):\n",
    "    def __init__(self, session_id, time_passed, *document_ids):\n",
    "        super().__init__(session_id, time_passed, \"C\", *document_ids)\n",
    "        self.document_id = document_ids[0]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"<Click in session #{} on #{}>\".format(self.session_id, self.document_id)\n",
    "        \n",
    "\n",
    "\n",
    "def read_yandex_data(path=\"./YandexRelPredChallenge.txt\"):\n",
    "    \"\"\" Parse the data set into an appropriate data structure. \"\"\"\n",
    "    data = YandexData()\n",
    "    current_session_id = 0\n",
    "    current_actions = []\n",
    "    \n",
    "    with codecs.open(path, \"rb\", \"utf-8\") as file:\n",
    "        for line in file.readlines():\n",
    "            columns = line.strip().split(\"\\t\")\n",
    "            columns = tuple(map(lambda x: int(x) if x not in (\"Q\", \"C\") else x, columns))  # Parse numbers\n",
    "            session_id, time_passed, action_type, *document_ids = columns\n",
    "            \n",
    "            # New session, create object, save it and start a new one\n",
    "            if session_id != current_session_id:\n",
    "                session = Session(current_session_id, current_actions)\n",
    "                data.add(session)\n",
    "                \n",
    "                current_session_id = session_id\n",
    "                current_actions = []\n",
    "            \n",
    "            if action_type == \"Q\":\n",
    "                # Get query id\n",
    "                serp_id, query_id, *document_ids = document_ids\n",
    "                current_actions.append(Query(session_id, time_passed, serp_id, query_id, *document_ids))\n",
    "            else:\n",
    "                # It's a click!\n",
    "                current_actions.append(Click(session_id, time_passed,  *document_ids))\n",
    "                \n",
    "    return data\n",
    "        \n",
    "yandex_data = read_yandex_data()\n",
    "print(yandex_data, \"\\n\")\n",
    "\n",
    "# You can now iterate over sessions in the data set like this:\n",
    "for session in yandex_data:\n",
    "    pass  # Do something\n",
    "\n",
    "# You iterate over slices of the data set:\n",
    "for session in yandex_data[5:10]:\n",
    "    print(session)\n",
    "    \n",
    "print(\"\")\n",
    "    \n",
    "# You can iterate over all the queries in the entire data set:\n",
    "for query in yandex_data.queries:\n",
    "    pass  # Do something\n",
    "\n",
    "# ... or of a single session\n",
    "for query in yandex_data[0].queries:\n",
    "    print(query)\n",
    "    \n",
    "# (Multiple queries with the same id might be the user clicking trough result pages?)\n",
    "    \n",
    "print(\"\")\n",
    "    \n",
    "for click in yandex_data[0].clicks:\n",
    "    print(click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 5 code\n",
    "# TODO: Santhosh: implement RCM\n",
    "# TODO: Dennis: one of the remaining 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original gammas: [0.7228685941560996, 0.9550206426485781, 0.15679397676336737, 0.5054048349637869, 0.07734960251792933, 0.2285534500144022, 0.9713126343535813, 0.9638235623860224, 0.5124243713663421, 0.11581772220687292]\n",
      "210044 unique document-query pairs found.\n",
      "\n",
      "Started iteration #1\n",
      "Updating gamma values...Gammas: [0.7958918212480104, 0.8985226868307781, 0.22145394564392562, 0.4054154052594505, 0.11836658416118319, 0.18577980215970266, 0.9137358338545628, 0.8865930769741743, 0.3641215971747069, 0.10798189567253529]\n",
      "\n",
      "Started iteration #2\n",
      "Updating gamma values...Gammas: [0.8287744053074233, 0.8142128055954483, 0.25433487524822473, 0.3406261626890063, 0.13937228588906705, 0.1634921728530837, 0.8035133457478645, 0.7629289154152298, 0.26277486729956157, 0.1038520633158986]\n",
      "\n",
      "Started iteration #3\n",
      "Updating gamma values...Gammas: [0.8432198879934597, 0.7148758256841774, 0.27104341845079977, 0.30025380281753994, 0.15028267844157514, 0.15172414954153418, 0.6503309169711358, 0.6147813567895295, 0.1990168867927789, 0.10158281920236627]\n",
      "\n",
      "Started iteration #4\n",
      "Updating gamma values...Gammas: [0.8483650390257058, 0.6209635006957717, 0.27921434122305344, 0.2758629100476288, 0.15597480517515983, 0.14547664097097854, 0.4937517343952239, 0.47351972569101136, 0.16088463098013592, 0.10030951208300572]\n",
      "\n",
      "Started iteration #5\n",
      "Updating gamma values...Gammas: [0.8487177671767859, 0.5455230647494119, 0.28283948494898004, 0.26141339475129843, 0.15895054841778394, 0.14213755763603214, 0.36609113500998597, 0.35938607607461925, 0.13874585755443214, 0.09959117362981192]\n",
      "\n",
      "Started iteration #6\n",
      "Updating gamma values...Gammas: [0.8466661706660131, 0.4912626237292531, 0.28408531974867235, 0.25296506755246523, 0.1605241022211535, 0.14034867443415827, 0.2762222968795299, 0.2769709104651213, 0.12612611954008252, 0.0991999449714132]\n",
      "\n",
      "Started iteration #7\n",
      "Updating gamma values...Gammas: [0.8435218770671606, 0.45482195197090897, 0.2841497120052268, 0.24808286281492803, 0.1613929461640986, 0.13940789302470585, 0.21841763330394479, 0.2216297519498831, 0.1190309379328703, 0.09901606309846445]\n",
      "\n",
      "Started iteration #8\n",
      "Updating gamma values...Gammas: [0.840012353100563, 0.43121573244026945, 0.2836893602623051, 0.24530430507933543, 0.1619255189397772, 0.13895087018271735, 0.1831815465932208, 0.18612595752007996, 0.11510157873466069, 0.09897374440078906]\n",
      "\n",
      "Started iteration #9\n",
      "Updating gamma values...Gammas: [0.8365307835468175, 0.41609054912406085, 0.2830501870627227, 0.24376294575008756, 0.16231257426482593, 0.13878468199122632, 0.16235910166631654, 0.16398358859749318, 0.1129765404486009, 0.09903406155486241]\n",
      "\n",
      "Started iteration #10\n",
      "Updating gamma values...Gammas: [0.8332741841366635, 0.4063146998011961, 0.2824005529077137, 0.24294785047952477, 0.1626491043092981, 0.13880295704388187, 0.15026310725570166, 0.15041549753139577, 0.11187860166940629, 0.09917174542151568]\n",
      "\n",
      "Started iteration #11\n",
      "Updating gamma values...Gammas: [0.8303254118018351, 0.3998430181813904, 0.2818107465966254, 0.24255750082849128, 0.16297917236943754, 0.13894346198026522, 0.14329568531612213, 0.1421969844379197, 0.11136586514512373, 0.0993688690737541]\n",
      "\n",
      "Started iteration #12\n",
      "Updating gamma values...Gammas: [0.8277035921913575, 0.3954072864854513, 0.2813001351671681, 0.2424133009558656, 0.16332039999792497, 0.13916715492318518, 0.13929423077239889, 0.13726257994153518, 0.11118691910063096, 0.09961181271933893]\n",
      "\n",
      "Started iteration #13\n",
      "Updating gamma values...Gammas: [0.8253949273724696, 0.392241369017638, 0.280864316622092, 0.24240900011173225, 0.1636772033009019, 0.13944782224397087, 0.1369947081180936, 0.13432644858654166, 0.11119813882001292, 0.09988975578074999]\n",
      "\n",
      "Started iteration #14\n",
      "Updating gamma values...Gammas: [0.823370835736651, 0.38988662652886197, 0.28049004069081285, 0.2424812275726131, 0.16404783021617286, 0.13976685048576318, 0.1356694594297496, 0.13260092398695816, 0.11131691742006716, 0.1001938763423516]\n",
      "\n",
      "Started iteration #15\n",
      "Updating gamma values...Gammas: [0.8215980338985501, 0.3880674195660344, 0.28016282368192696, 0.24259227311882897, 0.16442801658515613, 0.14011048261801615, 0.13490280351626846, 0.13160772163142825, 0.11149531995267078, 0.10051688486228842]\n",
      "\n",
      "Started iteration #16\n",
      "Updating gamma values...Gammas: [0.8200437085769269, 0.3866156148373446, 0.27987032927331235, 0.2427199287675082, 0.16481282302454178, 0.1404682911492057, 0.13445794026584748, 0.131057613339885, 0.11170524324186788, 0.10085272261451386]\n",
      "\n",
      "Started iteration #17\n",
      "Updating gamma values...Gammas: [0.8186778570437765, 0.38542614970334815, 0.2796034123667846, 0.24285140978136613, 0.16519750900915114, 0.14083226503737373, 0.13419986876941473, 0.13077586598124719, 0.11193003175420867, 0.10119634629692052]\n",
      "\n",
      "Started iteration #18\n",
      "Updating gamma values...Gammas: [0.8174740951575575, 0.38443127587133286, 0.27935598954804947, 0.24297965904450416, 0.16557790781887613, 0.14119622104304763, 0.13405133738697603, 0.1306567757556223, 0.11215971415699001, 0.10154356213998031]\n",
      "\n",
      "Started iteration #19\n",
      "Updating gamma values...Gammas: [0.8164096986246907, 0.3835857046874067, 0.2791244269376099, 0.24310107330386993, 0.16595055007277434, 0.14155539756902485, 0.1339678535382608, 0.1306361973290217, 0.11238827503549836, 0.10189089282313293]\n",
      "\n",
      "Started iteration #20\n",
      "Updating gamma values...Gammas: [0.8154653031281834, 0.3828580084156502, 0.2789068235913639, 0.24321409956099835, 0.1663126662758171, 0.14190615876774024, 0.1339235555261635, 0.13067502696923491, 0.11261207596873113, 0.10223546938193336]\n",
      "\n",
      "Started iteration #21\n",
      "Updating gamma values...Gammas: [0.8146244857537446, 0.3822255840995746, 0.2787023700508321, 0.24331837473151602, 0.16666213572396119, 0.14224577028060903, 0.13390323118898664, 0.13074929191708806, 0.11282893028236436, 0.1025749433358789]\n",
      "\n",
      "Started iteration #22\n",
      "Updating gamma values...Gammas: [0.813873335505761, 0.3816716459173706, 0.2785108478655292, 0.2434142058943942, 0.16699741548381672, 0.14257222460267616, 0.13389780229203294, 0.13084420258254167, 0.11303755302591752, 0.10290741486524517]\n",
      "\n",
      "Started iteration #23\n",
      "Updating gamma values...Gammas: [0.8132000594764347, 0.3811833806167305, 0.27833227812085964, 0.24350226071938819, 0.16731746542285267, 0.14288410261563697, 0.13390176041215374, 0.13095057528831808, 0.11323722881950389, 0.10323137302821972]\n",
      "\n",
      "Started iteration #24\n",
      "Updating gamma values...Gammas: [0.8125946403739298, 0.3807507793736994, 0.27816670057463583, 0.24358338373335361, 0.16762167609197245, 0.14318046244276053, 0.13391170231058117, 0.13106267190950419, 0.11342760794095151, 0.10354564452521677]\n",
      "\n",
      "Started iteration #25\n",
      "Updating gamma values...Gammas: [0.8120485466687463, 0.3803658716397388, 0.2780140546947185, 0.24365848574281637, 0.16790980172799325, 0.14346074941420556, 0.13392548623957876, 0.13117688726157545, 0.11360857908227444, 0.10384934839895756]\n",
      "\n",
      "Started iteration #26\n",
      "Updating gamma values...Gammas: [0.8115544906109429, 0.38002220480546495, 0.2778741323715246, 0.2437284755575881, 0.16818189863294622, 0.14372472254689642, 0.1339417404254976, 0.13129094527993196, 0.11378018871867544, 0.10414185503852263]\n",
      "\n",
      "Started iteration #27\n",
      "Updating gamma values...Gammas: [0.8111062274727618, 0.37971447937261416, 0.27774657564616917, 0.24379421719023114, 0.16843826853618846, 0.14397239402026324, 0.1339595725927257, 0.1314034023262703, 0.113942589282164, 0.10442274868668745]\n",
      "\n",
      "Started iteration #28\n",
      "Updating gamma values...Gammas: [0.8106983893279172, 0.3794382861695442, 0.2776308987982285, 0.24385650371792478, 0.16867940657828837, 0.1442039789164063, 0.1339783952927385, 0.13151333761290002, 0.11409600537349783, 0.10469179321123744]\n",
      "\n",
      "Started iteration #29\n",
      "Updating gamma values...Gammas: [0.8103263473713009, 0.37918991296926907, 0.27752652051402826, 0.24391604295802333, 0.16890595385536553, 0.14441985311675115, 0.1339978187435253, 0.13162015916330877, 0.11424071135584563, 0.10494890118690664]\n",
      "\n",
      "Started iteration #30\n",
      "Updating gamma values...Gammas: [0.8099860976814504, 0.3789661998464246, 0.27743279732374804, 0.24397345181804161, 0.16911865476204468, 0.1446205177621659, 0.13401758362841176, 0.13172348233157166, 0.11437701613194654, 0.10519410640649303]\n",
      "[0.3789661998464246, 0.27743279732374804, 0.24397345181804161, 0.16911865476204468, 0.1446205177621659, 0.13401758362841176, 0.13172348233157166, 0.11437701613194654, 0.10519410640649303, 0.4194363975319302]\n"
     ]
    }
   ],
   "source": [
    "# Has to do do three things\n",
    "# TODO: method to estimate parameters from training data\n",
    "# TODO: method that predicts click probability given ranked list\n",
    "# TODO: method to decide whether a document is clicked or not \n",
    "\n",
    "import abc\n",
    "import random\n",
    "\n",
    "class ClickModel:\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def estimate_parameters(self, data, **params):\n",
    "        \"\"\"Estimate the parameters of the model using the training data\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def predict_click_prob(self, rankings):\n",
    "        \"\"\"Return a list of probabilities of the document being clicked\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def simulate_clicks(self, rankings):\n",
    "        \"\"\" Determine which documents will be clicked based on the probabilities. \"\"\"\n",
    "        pass\n",
    "\n",
    "class RandomClickModel(ClickModel):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.click_prob = None\n",
    "    \n",
    "    def estimate_parameters(self, data, **params):\n",
    "        n_clicks = 0\n",
    "        n_docs = 0\n",
    "        \n",
    "        for session in data:\n",
    "            n_clicks += len(list(session.clicks))\n",
    "            n_docs += len(list(session.documents))\n",
    "            \n",
    "        self.click_prob = n_clicks / n_docs\n",
    "        \n",
    "    def predict_click_prob(self, rankings):\n",
    "        return [(rank, self.click_prob) for rank in rankings]\n",
    "    \n",
    "    def simulate_clicks(self, rankings):\n",
    "        return [(rank, random.random() <= self.click_prob) for rank in rankings]\n",
    "            \n",
    "class PositionBasedModel(RandomClickModel):\n",
    "    def __init__(self):\n",
    "        self.click_prob = None\n",
    "        self.alphas = None\n",
    "        self.gammas = None\n",
    "        \n",
    "    def estimate_parameters(self, data, iterations=25, **params):\n",
    "        super().estimate_parameters(data)  # Estimate click probability like in the random click model\n",
    "        \n",
    "        # Initializing attractiveness and examination probabilities\n",
    "        alphas = defaultdict(lambda: random.random())  # attractiveness\n",
    "        gammas = defaultdict(lambda: random.random())  # examination\n",
    "        \n",
    "        print(\"Original gammas: {}\".format([gammas[rank] for rank in range(10)]))\n",
    "        \n",
    "        # Get all combinations of documents u and queries q that exist inside the data set first\n",
    "        query_document_pairs = set()\n",
    "        for query in data.queries:\n",
    "            for document_id in query.document_ids:\n",
    "                query_document_pairs.add((query.query_id, document_id))\n",
    "            \n",
    "        print(\"{} unique document-query pairs found.\".format(len(query_document_pairs)))\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            print(\"\\r\\nStarted iteration #{}\".format(i+1))\n",
    "            \n",
    "            # Update alphas\n",
    "            print(\"\\rUpdating alpha values...\", flush=True, end=\"\")\n",
    "            for query_id, document_id in query_document_pairs:\n",
    "                relevant_sessions = [\n",
    "                    data.sessions[session_id] for session_id in data.querydocid2sessions[(query_id, document_id)]\n",
    "                ]\n",
    "                \n",
    "                # Update alpha\n",
    "                session_sum_alpha = 0\n",
    "                for session in relevant_sessions:\n",
    "                    rank = session.rank_of_document(document_id)\n",
    "                    click = 1 if session.has_been_clicked(document_id) else 0  # c_u^(s)\n",
    "                    session_sum_alpha += click + (1 - click) * ((1 - gammas[rank]) * alphas[(query_id, document_id)]) / (1 - gammas[rank] * alphas[(query_id, document_id)])\n",
    "                \n",
    "                try:\n",
    "                    session_sum_alpha /= len(relevant_sessions)\n",
    "                    alphas[(query_id, document_id)] = session_sum_alpha\n",
    "                except ZeroDivisonError:\n",
    "                    alphas[(query_id, document_id)] = 0\n",
    "                \n",
    "            # Update gammas\n",
    "            print(\"\\rUpdating gamma values...\", flush=True, end=\"\")\n",
    "            for rank in gammas.keys():\n",
    "                session_sum_gamma = 0\n",
    "                for session in data:\n",
    "                    \n",
    "                    try:\n",
    "                        document_id = session.document_at_rank(rank)\n",
    "                    except IndexError:\n",
    "                        # This rank doesn't appear in this session's query\n",
    "                        continue\n",
    "                        \n",
    "                    click = 1 if session.has_been_clicked(document_id) else 0  # c_u^(s)\n",
    "                    session_sum_gamma += click + (1 - click) * ((1 - alphas[(query_id, document_id)]) * gammas[rank]) / (1 - gammas[rank] * alphas[(query_id, document_id)])\n",
    "                \n",
    "                try:\n",
    "                    session_sum_gamma /= len(data)\n",
    "                    gammas[rank] = session_sum_gamma\n",
    "                except ZeroDivisonError:\n",
    "                    gammas[rank] = 0 \n",
    "                    \n",
    "            print(\"Gammas: {}\".format([gammas[rank] for rank in range(10)]))\n",
    "                \n",
    "        self.alphas = alphas\n",
    "        self.gammas = gammas\n",
    "        \n",
    "    def simulate_clicks(self, rankings):\n",
    "        # Because this is a simplified model, we use 1 as the attractiveness parameter\n",
    "        return [(rank, random.random() <= self.gammas[rank] * 1) for rank in rankings]\n",
    "    \n",
    "        \n",
    "#rand_model = RandomClickModel()\n",
    "#rand_model.estimate_parameters(yandex_data)\n",
    "\n",
    "position_model = PositionBasedModel()\n",
    "position_model.estimate_parameters(yandex_data, iterations=30)\n",
    "\n",
    "print([position_model.gammas[rank] for rank in range(1, 11)])\n",
    "\n",
    "#for P, E in simulations[:20]:\n",
    "#    print(\n",
    "#        \"{}:\\n\\tClick probs:\\n\\t\\t{}\\n\\tClicks:\\n\\t\\t{}\\n\".format(\n",
    "#            P,\n",
    "#            \"\\n\\t\\t\".join([\"{}/{}\".format(a, b) for a, b in rand_model.predict_click_prob(P)]),\n",
    "#            \"\\n\\t\\t\".join([\"{}/{}\".format(a, b) for a, b in rand_model.simulate_clicks(P)])\n",
    "#        )\n",
    "#    )\n",
    "#    \n",
    "#    print(\n",
    "#        \"{}:\\n\\tClick probs:\\n\\t\\t{}\\n\\tClicks:\\n\\t\\t{}\\n\".format(\n",
    "#            E,\n",
    "#            \"\\n\\t\\t\".join([\"{}/{}\".format(a, b) for a, b in rand_model.predict_click_prob(E)]),\n",
    "#            \"\\n\\t\\t\".join([\"{}/{}\".format(a, b) for a, b in rand_model.simulate_clicks(E)])\n",
    "#        )\n",
    "#    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Simulate Interleaving Experiment (10 points)\n",
    "Having implemented the click models, it is time to run the simulated experiment.\n",
    "\n",
    "For each of interleaved ranking run N simulations for each one of the click models implemented and measure the proportion p of wins for E.\n",
    "(Note 7: Some of the models above include an attractiveness parameter 𝑎uq. Use the relevance label to assign this parameter by setting 𝑎uq for a document u in the ranked list accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Stian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Results and Analysis (30 points)\n",
    "Compare the results of the offline experiments (i.e. the values of the 𝛥measure) with the results of the online experiment (i.e. proportion of wins), analyze them and reach your conclusions regarding their agreement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 7 code and markdown\n",
    "# TODO: we should probably all contribute to this part"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
