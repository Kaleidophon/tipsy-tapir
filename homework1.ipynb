{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Information retrieval --- Module 1: Evaulation\n",
    "Santosh Kumar Rajamanickam, Dennis Ulmer and Stian Steinbakken\n",
    "\n",
    "Maybe insert a small introduction here? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical part [15pts]\n",
    "### 1 Hypothesis Testing --- The problem of multiple comparisons. \n",
    "How many hypothesis tests, m, does it take to get to (with Type I error for each test = α):\n",
    "P(mth experiment gives significant result | m experiments lacking power to reject H0)?\n",
    "P(at least one significant result | m experiments lacking power to reject H0)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Bias and unfairness in Interleaving experiments [10 points]\n",
    "Balance interleaving has been shown to be biased in a number of corner cases. An example was given during the lecture with two ranked lists of length 3 being interleaved, and a randomly clicking population of users that resulted in algorithm A winning ⅔ of the time, even though in theory the percentage of wins should be 50% for both algorithms. Can you come up with a situation of two ranked lists of length 3 and a distribution of clicks over them for which Team-draft interleaving is unfair to the better algorithm?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental part [85 pts] \n",
    "Step 1: Simulate Rankings of Relevance for E and P (5 points)\n",
    "In the first step you will generate pairs of rankings of relevance, for the production P and experimental E, respectively, for a hypothetical query q. Assume a 3-graded relevance, i.e. {N, R, HR}. Construct all possible P and E ranking pairs of length 5. This step should give you about.\n",
    "\n",
    "Example:\n",
    "P: {N N N N N}\n",
    "E: {N N N N R}\n",
    "…\n",
    "P: {HR HR HR HR R}\n",
    "E: {HR HR HR HR HR}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 simulations:\n",
      "\n",
      "('P:', ['N', 'N', 'N', 'N', 'N'], 'E:', ['N', 'N', 'N', 'N', 'N'])\n",
      "('P:', ['N', 'N', 'N', 'N', 'N'], 'E:', ['N', 'N', 'N', 'N', 'R'])\n",
      "('P:', ['N', 'N', 'N', 'N', 'N'], 'E:', ['N', 'N', 'N', 'N', 'HR'])\n",
      "('P:', ['N', 'N', 'N', 'N', 'N'], 'E:', ['N', 'N', 'N', 'R', 'N'])\n",
      "('P:', ['N', 'N', 'N', 'N', 'N'], 'E:', ['N', 'N', 'N', 'R', 'R'])\n",
      "('P:', ['N', 'N', 'N', 'N', 'N'], 'E:', ['N', 'N', 'N', 'R', 'HR'])\n",
      "('P:', ['N', 'N', 'N', 'N', 'N'], 'E:', ['N', 'N', 'N', 'HR', 'N'])\n",
      "('P:', ['N', 'N', 'N', 'N', 'N'], 'E:', ['N', 'N', 'N', 'HR', 'R'])\n",
      "('P:', ['N', 'N', 'N', 'N', 'N'], 'E:', ['N', 'N', 'N', 'HR', 'HR'])\n",
      "('P:', ['N', 'N', 'N', 'N', 'N'], 'E:', ['N', 'N', 'R', 'N', 'N'])\n",
      "\n",
      "Last 10 simulations:\n",
      "\n",
      "('P:', ['HR', 'HR', 'HR', 'HR', 'HR'], 'E:', ['HR', 'HR', 'R', 'HR', 'HR'])\n",
      "('P:', ['HR', 'HR', 'HR', 'HR', 'HR'], 'E:', ['HR', 'HR', 'HR', 'N', 'N'])\n",
      "('P:', ['HR', 'HR', 'HR', 'HR', 'HR'], 'E:', ['HR', 'HR', 'HR', 'N', 'R'])\n",
      "('P:', ['HR', 'HR', 'HR', 'HR', 'HR'], 'E:', ['HR', 'HR', 'HR', 'N', 'HR'])\n",
      "('P:', ['HR', 'HR', 'HR', 'HR', 'HR'], 'E:', ['HR', 'HR', 'HR', 'R', 'N'])\n",
      "('P:', ['HR', 'HR', 'HR', 'HR', 'HR'], 'E:', ['HR', 'HR', 'HR', 'R', 'R'])\n",
      "('P:', ['HR', 'HR', 'HR', 'HR', 'HR'], 'E:', ['HR', 'HR', 'HR', 'R', 'HR'])\n",
      "('P:', ['HR', 'HR', 'HR', 'HR', 'HR'], 'E:', ['HR', 'HR', 'HR', 'HR', 'N'])\n",
      "('P:', ['HR', 'HR', 'HR', 'HR', 'HR'], 'E:', ['HR', 'HR', 'HR', 'HR', 'R'])\n",
      "('P:', ['HR', 'HR', 'HR', 'HR', 'HR'], 'E:', ['HR', 'HR', 'HR', 'HR', 'HR'])\n"
     ]
    }
   ],
   "source": [
    "# Step 1 code\n",
    "\n",
    "rankings = [\"N\", \"R\", \"HR\"]\n",
    "\n",
    "possible_rankings = []\n",
    "\n",
    "# Create all possible rankings of length 5\n",
    "for i in range(len(rankings)):\n",
    "    for j in range(len(rankings)):\n",
    "        for k in range(len(rankings)):\n",
    "            for l in range(len(rankings)):\n",
    "                for m in range(len(rankings)):\n",
    "                    possible_rankings.append([rankings[i], rankings[j], \\\n",
    "                            rankings[k], rankings[l], rankings[m]])\n",
    "\n",
    "simulations = []\n",
    "\n",
    "# Simulate all possible combinations of possible rankings for both E and P\n",
    "for P_ranking in possible_rankings:\n",
    "    for E_ranking in possible_rankings:\n",
    "        simulations.append((P_ranking, E_ranking))\n",
    "        \n",
    "# We print the first and last 10 pairs as a sample:\n",
    "print(\"First 10 simulations:\\n\")\n",
    "for P_ranking, E_ranking in simulations[:10]:\n",
    "    print(\"P:\", P_ranking, \"E:\", E_ranking)\n",
    "    \n",
    "print(\"\\nLast 10 simulations:\\n\")\n",
    "for P_ranking, E_ranking in simulations[-10:]:\n",
    "    print(\"P:\", P_ranking, \"E:\", E_ranking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
